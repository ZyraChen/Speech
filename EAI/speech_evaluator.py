"""
æ¼”è®²ç¨¿è´¨é‡è¯„ä¼°ç³»ç»Ÿ - æ”¯æŒPDFå¹»ç¯ç‰‡
Presentation Speech Quality Evaluation System with PDF Support
"""

import json
import re
from typing import Dict, List, Tuple
from collections import Counter
import math


class SpeechEvaluator:
    """æ¼”è®²ç¨¿è¯„ä¼°å™¨ - æ”¯æŒPDFæå–çš„æ–‡æœ¬"""

    def __init__(self, slides_text: str, speech_json_str: str):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            slides_text: ä»PDFæå–çš„å¹»ç¯ç‰‡æ–‡æœ¬å†…å®¹
            speech_json_str: æ¼”è®²ç¨¿JSONå­—ç¬¦ä¸²
        """
        self.slides_content = slides_text

        # è§£æJSON,å¤„ç†å¯èƒ½çš„markdownä»£ç å—
        speech_json_str = speech_json_str.strip()
        if speech_json_str.startswith('```json'):
            speech_json_str = speech_json_str[7:]
        if speech_json_str.startswith('```'):
            speech_json_str = speech_json_str[3:]
        if speech_json_str.endswith('```'):
            speech_json_str = speech_json_str[:-3]
        speech_json_str = speech_json_str.strip()

        self.speech_data = json.loads(speech_json_str)
        self.plan = self.speech_data.get('plan', [])
        self.script = self.speech_data.get('script', [])

    # ============ 1. å†…å®¹ä¸€è‡´æ€§è¯„ä¼° ============

    def evaluate_content_consistency(self) -> Dict:
        """è¯„ä¼°å†…å®¹ä¸€è‡´æ€§"""

        # æå–å¹»ç¯ç‰‡å…³é”®è¯å’Œå…³é”®æ¦‚å¿µ
        slides_keywords = self._extract_keywords(self.slides_content)
        slides_concepts = self._extract_key_concepts(self.slides_content)

        # æå–æ¼”è®²ç¨¿å…³é”®è¯å’Œæ¦‚å¿µ
        speech_text = ' '.join([s['text'] for s in self.script])
        speech_keywords = self._extract_keywords(speech_text)
        speech_concepts = self._extract_key_concepts(speech_text)

        # è®¡ç®—è¦†ç›–ç‡
        keyword_coverage = self._calculate_coverage(slides_keywords, speech_keywords)
        concept_coverage = self._calculate_coverage(slides_concepts, speech_concepts)

        # æ£€æŸ¥å¹»ç¯ç‰‡æ ‡é¢˜è¦†ç›–
        slide_coverage = self._check_slide_title_coverage()

        # æ£€æµ‹æ½œåœ¨å¹»è§‰
        hallucination_risk = self._detect_hallucination_risk(
            slides_keywords, speech_keywords
        )

        # æ£€æŸ¥å…³é”®æ•°æ®å’Œäº‹å®
        fact_accuracy = self._check_fact_consistency()

        return {
            'keyword_coverage': keyword_coverage,
            'concept_coverage': concept_coverage,
            'slide_title_coverage': slide_coverage,
            'fact_accuracy': fact_accuracy,
            'hallucination_risk_score': hallucination_risk,
            'overall_score': (keyword_coverage + concept_coverage +
                            slide_coverage + fact_accuracy +
                            (1 - hallucination_risk)) / 5
        }

    def _extract_keywords(self, text: str) -> Counter:
        """æå–å…³é”®è¯"""
        # è½¬å°å†™
        text = text.lower()
        # æå–è‹±æ–‡å•è¯å’Œä¸­æ–‡è¯ç»„
        # è‹±æ–‡å•è¯
        english_words = re.findall(r'\b[a-z]{4,}\b', text)
        # ä¸­æ–‡è¯ç»„(2-4å­—)
        chinese_words = re.findall(r'[\u4e00-\u9fff]{2,4}', text)

        # åˆå¹¶
        all_words = english_words + chinese_words

        # è¿‡æ»¤åœç”¨è¯
        stopwords = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at',
            'to', 'for', 'of', 'with', 'by', 'from', 'is', 'are',
            'was', 'were', 'be', 'been', 'have', 'has', 'had',
            'this', 'that', 'these', 'those', 'will', 'would',
            'è¿™ä¸ª', 'é‚£ä¸ª', 'å¯ä»¥', 'æˆ‘ä»¬', 'ä»–ä»¬', 'ä»€ä¹ˆ', 'æ€ä¹ˆ'
        }

        keywords = [w for w in all_words if w not in stopwords]
        return Counter(keywords)

    def _extract_key_concepts(self, text: str) -> set:
        """æå–å…³é”®æ¦‚å¿µ(å¤šè¯çŸ­è¯­)"""
        # æå–ä¸“ä¸šæœ¯è¯­å’Œé‡è¦æ¦‚å¿µ
        # è‹±æ–‡: å¤§å†™å­—æ¯å¼€å¤´çš„çŸ­è¯­ã€è¿å­—ç¬¦è¯ç»„
        english_concepts = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        english_concepts += re.findall(r'\b[a-z]+-[a-z]+(?:-[a-z]+)*\b', text)

        # ä¸­æ–‡: å¸¸è§çš„ä¸“ä¸šæœ¯è¯­æ¨¡å¼
        chinese_concepts = re.findall(r'[\u4e00-\u9fff]{3,8}', text)

        # æå–ç¼©å†™è¯
        abbreviations = re.findall(r'\b[A-Z]{2,}\b', text)

        all_concepts = set(english_concepts + chinese_concepts + abbreviations)

        # è¿‡æ»¤å¤ªå¸¸è§çš„è¯
        filtered = {c for c in all_concepts if len(c) >= 3}
        return filtered

    def _calculate_coverage(self, source_items, target_items) -> float:
        """è®¡ç®—è¦†ç›–ç‡"""
        if not source_items:
            return 1.0

        if isinstance(source_items, Counter):
            source_keys = set(source_items.keys())
            target_keys = set(target_items.keys()) if isinstance(target_items, Counter) else set(target_items)
            covered = len(source_keys & target_keys)
            return covered / len(source_keys)
        else:
            covered = len(source_items & target_items)
            return covered / len(source_items)

    def _check_slide_title_coverage(self) -> float:
        """æ£€æŸ¥å¹»ç¯ç‰‡æ ‡é¢˜è¦†ç›–ç‡"""
        # ä»planä¸­æå–æ ‡é¢˜
        plan_titles = [p.get('title', '') for p in self.plan if p.get('title')]

        if not plan_titles:
            return 1.0

        # åœ¨æ¼”è®²ç¨¿ä¸­æŸ¥æ‰¾æ ‡é¢˜å…³é”®è¯
        speech_text = ' '.join([s['text'] for s in self.script]).lower()

        covered = 0
        for title in plan_titles:
            # æå–æ ‡é¢˜ä¸­çš„å…³é”®è¯
            title_words = re.findall(r'\b\w+\b', title.lower())
            # è‡³å°‘ä¸€åŠçš„å…³é”®è¯å‡ºç°åœ¨æ¼”è®²ç¨¿ä¸­
            matches = sum(1 for word in title_words if word in speech_text and len(word) > 3)
            if matches >= len(title_words) / 2:
                covered += 1

        return covered / len(plan_titles)

    def _check_fact_consistency(self) -> float:
        """æ£€æŸ¥äº‹å®ä¸€è‡´æ€§"""
        # æå–æ•°å­—ã€å¹´ä»½ã€äººåç­‰å…³é”®äº‹å®
        slides_numbers = re.findall(r'\b\d{4}\b|\b\d+%\b|\b\d+\.\d+\b', self.slides_content)
        slides_names = re.findall(r'\b[A-Z][a-z]+\s+[A-Z][a-z]+\b', self.slides_content)

        speech_text = ' '.join([s['text'] for s in self.script])
        speech_numbers = re.findall(r'\b\d{4}\b|\b\d+%\b|\b\d+\.\d+\b', speech_text)
        speech_names = re.findall(r'\b[A-Z][a-z]+\s+[A-Z][a-z]+\b', speech_text)

        # æ£€æŸ¥å¹»ç¯ç‰‡ä¸­çš„äº‹å®æ˜¯å¦åœ¨æ¼”è®²ç¨¿ä¸­è¢«æåŠ
        total_facts = len(slides_numbers) + len(slides_names)
        if total_facts == 0:
            return 1.0

        matched_facts = 0
        matched_facts += sum(1 for num in slides_numbers if num in speech_text)
        matched_facts += sum(1 for name in slides_names if name in speech_text)

        return matched_facts / total_facts

    def _detect_hallucination_risk(self, source_keywords: Counter,
                                   target_keywords: Counter) -> float:
        """æ£€æµ‹å¹»è§‰é£é™©"""
        if not target_keywords:
            return 0.0

        # æ¼”è®²ç¨¿ä¸­å‡ºç°ä½†å¹»ç¯ç‰‡ä¸­æ²¡æœ‰çš„å…³é”®è¯
        new_keywords = set(target_keywords.keys()) - set(source_keywords.keys())

        # è®¡ç®—æ–°è¯å æ¯”
        risk_ratio = len(new_keywords) / len(target_keywords)

        # æ­£å¸¸åŒ–:æ–°è¯å æ¯”åœ¨30%ä»¥å†…æ˜¯åˆç†çš„(é€‚å½“æ‰©å±•)
        # è¶…è¿‡30%è®¤ä¸ºé£é™©å¢åŠ 
        if risk_ratio <= 0.3:
            return risk_ratio / 0.3 * 0.3  # æ˜ å°„åˆ°0-0.3
        else:
            return 0.3 + (risk_ratio - 0.3) / 0.7 * 0.7  # æ˜ å°„åˆ°0.3-1.0

    # ============ 2. ç»“æ„åˆç†æ€§è¯„ä¼° ============

    def evaluate_structure(self) -> Dict:
        """è¯„ä¼°ç»“æ„åˆç†æ€§"""

        coherence_score = self._evaluate_coherence()
        time_balance = self._evaluate_time_balance()
        transition_score = self._evaluate_transitions()
        organization_score = self._evaluate_organization()

        return {
            'coherence_score': coherence_score,
            'time_balance_score': time_balance,
            'transition_score': transition_score,
            'organization_score': organization_score,
            'overall_score': (coherence_score + time_balance +
                            transition_score + organization_score) / 4
        }

    def _evaluate_coherence(self) -> float:
        """è¯„ä¼°é€»è¾‘è¿è´¯æ€§"""
        slide_numbers = [p['slide'] for p in self.plan]
        script_slides = [s['slide'] for s in self.script]

        # æ£€æŸ¥æ˜¯å¦é¡ºåºåˆç†
        is_sequential = all(slide_numbers[i] <= slide_numbers[i+1]
                           for i in range(len(slide_numbers)-1))
        script_sequential = all(script_slides[i] <= script_slides[i+1]
                               for i in range(len(script_slides)-1))

        # æ£€æŸ¥æ˜¯å¦æ¯å¼ å¹»ç¯ç‰‡éƒ½æœ‰å¯¹åº”çš„æ¼”è®²å†…å®¹
        plan_slides = set(slide_numbers)
        script_slide_set = set(script_slides)
        coverage = len(plan_slides & script_slide_set) / len(plan_slides) if plan_slides else 1.0

        return (float(is_sequential) + float(script_sequential) + coverage) / 3

    def _parse_duration(self, duration_str: str) -> float:
        """
        è§£ææ—¶é—´å­—ç¬¦ä¸²,ç»Ÿä¸€è½¬æ¢ä¸ºåˆ†é’Ÿ
        æ”¯æŒæ ¼å¼: "2 minutes", "30 seconds", "1.5 minutes", "90s", "2min"
        """
        if not duration_str:
            return 0.0

        duration_str = duration_str.lower().strip()

        # æå–æ•°å­—
        number_match = re.search(r'(\d+\.?\d*)', duration_str)
        if not number_match:
            return 0.0

        number = float(number_match.group(1))

        # åˆ¤æ–­å•ä½
        if 'second' in duration_str or duration_str.endswith('s'):
            # ç§’è½¬åˆ†é’Ÿ
            return number / 60
        elif 'hour' in duration_str or duration_str.endswith('h'):
            # å°æ—¶è½¬åˆ†é’Ÿ
            return number * 60
        else:
            # é»˜è®¤ä¸ºåˆ†é’Ÿ (minute, min, m)
            return number

    def _evaluate_time_balance(self) -> float:
        """è¯„ä¼°æ—¶é—´åˆ†é…å¹³è¡¡æ€§"""
        durations = []
        for p in self.plan:
            duration_str = p.get('duration', '0 minute')
            duration_minutes = self._parse_duration(duration_str)
            if duration_minutes > 0:
                durations.append(duration_minutes)

        if not durations or len(durations) < 3:
            return 1.0

        # è®¡ç®—å˜å¼‚ç³»æ•°(æ ‡å‡†å·®/å‡å€¼)
        mean = sum(durations) / len(durations)
        if mean == 0:
            return 0.0

        variance = sum((x - mean) ** 2 for x in durations) / len(durations)
        std_dev = math.sqrt(variance)
        cv = std_dev / mean

        # å˜å¼‚ç³»æ•°å°äº0.5è¾ƒå¥½
        balance_score = max(0, 1 - cv)
        return min(balance_score, 1.0)

    def _evaluate_transitions(self) -> float:
        """è¯„ä¼°è¿‡æ¸¡è‡ªç„¶æ€§"""
        transition_phrases = [
            "let's", 'next', 'now', 'moving', 'turn to', 'consider',
            'however', 'therefore', 'furthermore', 'additionally',
            'in conclusion', 'to summarize', 'brings us to',
            'æ¥ä¸‹æ¥', 'ç°åœ¨', 'ç„¶å', 'å› æ­¤', 'æ­¤å¤–', 'æ€»ä¹‹',
            'è®©æˆ‘ä»¬', 'ä¸‹é¢', 'é¦–å…ˆ', 'å…¶æ¬¡', 'æœ€å'
        ]

        transition_count = 0
        for i, script in enumerate(self.script):
            if i == 0:  # è·³è¿‡ç¬¬ä¸€å¼ 
                continue
            text = script['text'].lower()
            # æ£€æŸ¥æ®µè½å¼€å¤´æ˜¯å¦æœ‰è¿‡æ¸¡è¯
            first_sentence = text.split('.')[0] if '.' in text else text
            if any(phrase in first_sentence.lower() for phrase in transition_phrases):
                transition_count += 1

        ideal_transitions = len(self.script) - 1
        return transition_count / ideal_transitions if ideal_transitions > 0 else 1.0

    def _evaluate_organization(self) -> float:
        """è¯„ä¼°æ•´ä½“ç»„ç»‡ç»“æ„"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼•è¨€ã€ä¸»ä½“ã€ç»“è®º
        has_intro = any('introduction' in p.get('title', '').lower() or
                       'intro' in p.get('title', '').lower() or
                       i == 0 for i, p in enumerate(self.plan))

        has_conclusion = any('conclusion' in p.get('title', '').lower() or
                            'summary' in p.get('title', '').lower() or
                            'q&a' in p.get('title', '').lower() or
                            i == len(self.plan) - 1
                            for i, p in enumerate(self.plan))

        has_body = len(self.plan) >= 3

        return (float(has_intro) + float(has_conclusion) + float(has_body)) / 3

    # ============ 3. è¯­è¨€è´¨é‡è¯„ä¼° ============

    def evaluate_language_quality(self) -> Dict:
        """è¯„ä¼°è¯­è¨€è´¨é‡"""

        clarity_score = self._evaluate_clarity()
        conversational_score = self._evaluate_conversational_style()
        vocabulary_richness = self._evaluate_vocabulary()
        professionalism = self._evaluate_professionalism()

        return {
            'clarity_score': clarity_score,
            'conversational_score': conversational_score,
            'vocabulary_richness': vocabulary_richness,
            'professionalism_score': professionalism,
            'overall_score': (clarity_score + conversational_score +
                            vocabulary_richness + professionalism) / 4
        }

    def _evaluate_clarity(self) -> float:
        """è¯„ä¼°æ¸…æ™°åº¦"""
        all_text = ' '.join([s['text'] for s in self.script])
        sentences = re.split(r'[.!?ã€‚!?]+', all_text)
        sentences = [s.strip() for s in sentences if s.strip()]

        if not sentences:
            return 0.0

        # è®¡ç®—å¹³å‡å¥å­é•¿åº¦
        avg_length = sum(len(s.split()) for s in sentences) / len(sentences)

        # ç†æƒ³å¥å­é•¿åº¦:12-25è¯
        if 12 <= avg_length <= 25:
            return 1.0
        elif avg_length < 12:
            return 0.7 + (avg_length / 12) * 0.3
        else:
            return max(0.3, 1 - (avg_length - 25) / 25)

    def _evaluate_conversational_style(self) -> float:
        """è¯„ä¼°å£è¯­åŒ–ç¨‹åº¦"""
        conversational_markers = [
            "let's", "we'll", "i'm", "you'll", "we're", "i'll",
            'today', 'now', 'here', 'our', 'my', 'your',
            'everyone', 'thank you', 'hello', 'hi',
            'å¤§å®¶', 'æˆ‘ä»¬', 'ä»Šå¤©', 'ç°åœ¨', 'è®©æˆ‘ä»¬',
            'ä½ ä»¬', 'å’±ä»¬', 'è¿™é‡Œ', 'é‚£ä¹ˆ'
        ]

        all_text = ' '.join([s['text'] for s in self.script]).lower()
        words = all_text.split()

        marker_count = sum(1 for word in words
                          if any(marker in word for marker in conversational_markers))

        # æ¯100è¯æœ‰2-6ä¸ªå£è¯­æ ‡è®°æ¯”è¾ƒç†æƒ³
        ratio = marker_count / len(words) * 100 if words else 0

        if 2 <= ratio <= 6:
            return 1.0
        elif ratio < 2:
            return ratio / 2
        else:
            return max(0.5, 1 - (ratio - 6) / 10)

    def _evaluate_vocabulary(self) -> float:
        """è¯„ä¼°è¯æ±‡ä¸°å¯Œåº¦"""
        all_text = ' '.join([s['text'] for s in self.script]).lower()
        # æå–æ‰€æœ‰è¯
        words = re.findall(r'\b[a-z]+\b', all_text)
        chinese_words = re.findall(r'[\u4e00-\u9fff]+', all_text)
        all_words = words + chinese_words

        if not all_words:
            return 0.0

        # ç±»å‹-è¯ä¾‹æ¯”
        unique_words = len(set(all_words))
        total_words = len(all_words)
        ttr = unique_words / total_words

        # TTRé€šå¸¸åœ¨0.35-0.65ä¹‹é—´
        if 0.35 <= ttr <= 0.65:
            return 1.0
        elif ttr < 0.35:
            return ttr / 0.35
        else:
            return max(0.6, 1 - (ttr - 0.65) / 0.35)

    def _evaluate_professionalism(self) -> float:
        """è¯„ä¼°ä¸“ä¸šæ€§"""
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å¹»ç¯ç‰‡ä¸­çš„ä¸“ä¸šæœ¯è¯­
        all_text = ' '.join([s['text'] for s in self.script])

        # ä»å¹»ç¯ç‰‡æå–çš„ä¸“ä¸šæœ¯è¯­
        technical_terms = [
            'llm', 'large language model', 'fact-checking', 'hallucination',
            'argumentation', 'evidence', 'verification', 'benchmark',
            'algorithm', 'dataset', 'evaluation', 'accuracy'
        ]

        term_usage = sum(1 for term in technical_terms if term in all_text.lower())

        # è‡³å°‘ä½¿ç”¨ä¸€åŠçš„ä¸“ä¸šæœ¯è¯­
        return min(term_usage / (len(technical_terms) / 2), 1.0)

    # ============ 4. ç»†èŠ‚ä¸°å¯Œåº¦è¯„ä¼° ============

    def evaluate_detail_richness(self) -> Dict:
        """è¯„ä¼°ç»†èŠ‚ä¸°å¯Œåº¦"""

        expansion_ratio = self._calculate_expansion_ratio()
        example_usage = self._check_example_usage()
        explanation_quality = self._evaluate_explanations()
        context_provision = self._evaluate_context()

        return {
            'expansion_ratio_score': expansion_ratio,
            'example_usage_score': example_usage,
            'explanation_quality': explanation_quality,
            'context_provision': context_provision,
            'overall_score': (expansion_ratio + example_usage +
                            explanation_quality + context_provision) / 4
        }

    def _calculate_expansion_ratio(self) -> float:
        """è®¡ç®—å†…å®¹æ‰©å±•æ¯”"""
        slides_words = len(self.slides_content.split())
        speech_words = len(' '.join([s['text'] for s in self.script]).split())

        if slides_words == 0:
            return 0.0

        ratio = speech_words / slides_words

        # ç†æƒ³æ‰©å±•æ¯”:1.5-3å€
        if 1.5 <= ratio <= 3:
            return 1.0
        elif ratio < 1.5:
            return ratio / 1.5
        else:
            return max(0.5, 1 - (ratio - 3) / 3)

    def _check_example_usage(self) -> float:
        """æ£€æŸ¥ä¾‹å­ä½¿ç”¨"""
        example_indicators = [
            'example', 'for instance', 'such as', 'like',
            'consider', "let's take", 'case', 'illustrate',
            'ä¾‹å¦‚', 'æ¯”å¦‚', 'ä¸¾ä¾‹', 'æ¡ˆä¾‹', 'è€ƒè™‘'
        ]

        all_text = ' '.join([s['text'] for s in self.script]).lower()

        example_count = sum(all_text.count(indicator)
                           for indicator in example_indicators)

        # æ¯4-5å¼ å¹»ç¯ç‰‡è‡³å°‘1ä¸ªä¾‹å­
        ideal_examples = len(self.script) / 4.5
        score = min(example_count / max(ideal_examples, 1), 1.0)

        return score

    def _evaluate_explanations(self) -> float:
        """è¯„ä¼°è§£é‡Šè´¨é‡"""
        explanation_markers = [
            'this means', 'in other words', 'specifically',
            'that is', 'namely', 'essentially', 'simply put',
            'ä¹Ÿå°±æ˜¯è¯´', 'æ¢å¥è¯è¯´', 'å…·ä½“æ¥è¯´', 'ç®€å•æ¥è¯´'
        ]

        all_text = ' '.join([s['text'] for s in self.script]).lower()

        explanation_count = sum(all_text.count(marker)
                               for marker in explanation_markers)

        # æ¯3å¼ å¹»ç¯ç‰‡è‡³å°‘1ä¸ªè§£é‡Š
        ideal_explanations = len(self.script) / 3
        score = min(explanation_count / max(ideal_explanations, 1), 1.0)

        return score

    def _evaluate_context(self) -> float:
        """è¯„ä¼°èƒŒæ™¯ä¿¡æ¯æä¾›"""
        # æ£€æŸ¥æ˜¯å¦æä¾›äº†èƒŒæ™¯ã€åŠ¨æœºã€æ„ä¹‰ç­‰ä¿¡æ¯
        context_keywords = [
            'background', 'motivation', 'why', 'important', 'challenge',
            'problem', 'goal', 'objective', 'significance',
            'èƒŒæ™¯', 'åŠ¨æœº', 'ä¸ºä»€ä¹ˆ', 'é‡è¦', 'æŒ‘æˆ˜', 'é—®é¢˜', 'ç›®æ ‡', 'æ„ä¹‰'
        ]

        all_text = ' '.join([s['text'] for s in self.script]).lower()

        context_count = sum(1 for keyword in context_keywords if keyword in all_text)

        # è‡³å°‘æåŠ3-5ä¸ªèƒŒæ™¯ç›¸å…³æ¦‚å¿µ
        return min(context_count / 4, 1.0)

    # ============ 5. æ—¶é—´è§„åˆ’è¯„ä¼° ============

    def evaluate_time_management(self) -> Dict:
        """è¯„ä¼°æ—¶é—´è§„åˆ’"""

        total_time = self._calculate_total_time()
        duration_appropriateness = self._evaluate_duration_appropriateness(total_time)
        time_distribution = self._evaluate_time_distribution()
        pace_consistency = self._evaluate_pace()

        return {
            'total_minutes': total_time,
            'duration_appropriateness': duration_appropriateness,
            'time_distribution_score': time_distribution,
            'pace_consistency': pace_consistency,
            'overall_score': (duration_appropriateness + time_distribution +
                            pace_consistency) / 3
        }

    def _calculate_total_time(self) -> float:
        """è®¡ç®—æ€»æ—¶é•¿(åˆ†é’Ÿ)"""
        total = 0.0
        for p in self.plan:
            duration_str = p.get('duration', '0 minute')
            total += self._parse_duration(duration_str)
        return total

    def _evaluate_duration_appropriateness(self, total_minutes: float) -> float:
        """è¯„ä¼°æ€»æ—¶é•¿åˆç†æ€§"""
        num_slides = len(self.plan)

        # ç†æƒ³æ—¶é•¿:æ¯å¼ 1-2.5åˆ†é’Ÿ
        ideal_min = num_slides * 1
        ideal_max = num_slides * 2.5

        if ideal_min <= total_minutes <= ideal_max:
            return 1.0
        elif total_minutes < ideal_min:
            return total_minutes / ideal_min
        else:
            return max(0.4, 1 - (total_minutes - ideal_max) / ideal_max)

    def _evaluate_time_distribution(self) -> float:
        """è¯„ä¼°æ—¶é—´åˆ†å¸ƒ"""
        durations = []
        for p in self.plan:
            duration_str = p.get('duration', '0 minute')
            duration_minutes = self._parse_duration(duration_str)
            if duration_minutes > 0:
                durations.append(duration_minutes)

        if len(durations) < 3:
            return 1.0

        # æ£€æŸ¥å¼€å¤´å’Œç»“å°¾æ˜¯å¦ç®€æ´
        intro_ok = durations[0] <= 2
        outro_ok = durations[-1] <= 2

        # æ£€æŸ¥ä¸­é—´éƒ¨åˆ†æ˜¯å¦å……å®
        middle_durations = durations[1:-1] if len(durations) > 2 else durations
        middle_ok = all(d >= 1 for d in middle_durations)

        return (float(intro_ok) + float(outro_ok) + float(middle_ok)) / 3

    def _evaluate_pace(self) -> float:
        """è¯„ä¼°èŠ‚å¥ä¸€è‡´æ€§"""
        durations = []
        for p in self.plan:
            duration_str = p.get('duration', '0 minute')
            duration_minutes = self._parse_duration(duration_str)
            if duration_minutes > 0:
                durations.append(duration_minutes)

        if not durations:
            return 1.0

        # æ£€æŸ¥æ˜¯å¦æœ‰æç«¯å€¼(è¿‡é•¿æˆ–è¿‡çŸ­)
        mean = sum(durations) / len(durations)
        extreme_count = sum(1 for d in durations if d > mean * 2 or d < mean * 0.5)

        # æç«¯å€¼è¶Šå°‘è¶Šå¥½
        return max(0, 1 - extreme_count / len(durations))

    # ============ ç»¼åˆè¯„ä¼° ============

    def evaluate_all(self) -> Dict:
        """æ‰§è¡Œæ‰€æœ‰è¯„ä¼°"""
        print("=" * 70)
        print("æ­£åœ¨è¯„ä¼°æ¼”è®²ç¨¿è´¨é‡...")
        print("=" * 70)

        results = {
            'content_consistency': self.evaluate_content_consistency(),
            'structure': self.evaluate_structure(),
            'language_quality': self.evaluate_language_quality(),
            'detail_richness': self.evaluate_detail_richness(),
            'time_management': self.evaluate_time_management()
        }

        # åŠ æƒè®¡ç®—æ€»åˆ†
        weights = {
            'content_consistency': 0.30,
            'structure': 0.25,
            'language_quality': 0.20,
            'detail_richness': 0.15,
            'time_management': 0.10
        }

        overall_score = sum(
            results[key]['overall_score'] * weights[key]
            for key in weights
        )

        results['overall_score'] = overall_score
        results['grade'] = self._get_grade(overall_score)
        results['weights'] = weights

        return results

    def _get_grade(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è·å–ç­‰çº§"""
        if score >= 0.90:
            return 'A+ (ä¼˜ç§€)'
        elif score >= 0.85:
            return 'A (ä¼˜ç§€)'
        elif score >= 0.80:
            return 'B+ (è‰¯å¥½)'
        elif score >= 0.75:
            return 'B (è‰¯å¥½)'
        elif score >= 0.70:
            return 'C+ (ä¸­ç­‰)'
        elif score >= 0.65:
            return 'C (ä¸­ç­‰)'
        elif score >= 0.60:
            return 'D (åŠæ ¼)'
        else:
            return 'F (ä¸åŠæ ¼)'

    def generate_report(self) -> str:
        """ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š"""
        results = self.evaluate_all()

        report = "\n" + "=" * 70 + "\n"
        report += " " * 20 + "æ¼”è®²ç¨¿è´¨é‡è¯„ä¼°æŠ¥å‘Š\n"
        report += " " * 20 + "Speech Quality Evaluation Report\n"
        report += "=" * 70 + "\n\n"

        # æ€»ä½“è¯„åˆ†
        report += f"ã€æ€»ä½“è¯„åˆ†ã€‘ {results['overall_score']:.1%}\n"
        report += f"ã€è¯„çº§ç­‰çº§ã€‘ {results['grade']}\n"
        total_time = self._calculate_total_time()
        report += f"ã€æ¼”è®²æ—¶é•¿ã€‘ {total_time:.1f}åˆ†é’Ÿ ({int(total_time * 60)}ç§’)\n"
        report += f"ã€å¹»ç¯ç‰‡æ•°ã€‘ {len(self.plan)}å¼ \n\n"

        # å„ç»´åº¦è¯„åˆ†å¯è§†åŒ–
        report += "-" * 70 + "\n"
        report += "å„ç»´åº¦å¾—åˆ†æ€»è§ˆ:\n"
        report += "-" * 70 + "\n"
        for key, weight in results['weights'].items():
            score = results[key]['overall_score']
            bar_length = int(score * 40)
            bar = "â–ˆ" * bar_length + "â–‘" * (40 - bar_length)
            name_map = {
                'content_consistency': 'å†…å®¹ä¸€è‡´æ€§',
                'structure': 'ç»“æ„åˆç†æ€§',
                'language_quality': 'è¯­è¨€è´¨é‡',
                'detail_richness': 'ç»†èŠ‚ä¸°å¯Œåº¦',
                'time_management': 'æ—¶é—´è§„åˆ’'
            }
            report += f"{name_map[key]:8s} ({weight:.0%}) [{bar}] {score:.1%}\n"

        report += "\n" + "=" * 70 + "\n"
        report += "è¯¦ç»†è¯„åˆ†åˆ†æ:\n"
        report += "=" * 70 + "\n\n"

        # 1. å†…å®¹ä¸€è‡´æ€§
        report += "ã€1. å†…å®¹ä¸€è‡´æ€§ã€‘ æƒé‡: 30%\n"
        report += "-" * 70 + "\n"
        cc = results['content_consistency']
        report += f"  å…³é”®è¯è¦†ç›–ç‡:     {cc['keyword_coverage']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if cc['keyword_coverage'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  æ¦‚å¿µè¦†ç›–ç‡:       {cc['concept_coverage']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if cc['concept_coverage'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  æ ‡é¢˜è¦†ç›–ç‡:       {cc['slide_title_coverage']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if cc['slide_title_coverage'] >= 0.8 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  äº‹å®å‡†ç¡®æ€§:       {cc['fact_accuracy']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if cc['fact_accuracy'] >= 0.8 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  å¹»è§‰é£é™©è¯„åˆ†:     {cc['hallucination_risk_score']:.1%}  "
        report += f"{'âœ“ é£é™©ä½' if cc['hallucination_risk_score'] <= 0.3 else 'âš  é£é™©è¾ƒé«˜'}\n"
        report += f"  ç»¼åˆå¾—åˆ†:         {cc['overall_score']:.1%}\n\n"

        # 2. ç»“æ„åˆç†æ€§
        report += "ã€2. ç»“æ„åˆç†æ€§ã€‘ æƒé‡: 25%\n"
        report += "-" * 70 + "\n"
        st = results['structure']
        report += f"  é€»è¾‘è¿è´¯æ€§:       {st['coherence_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if st['coherence_score'] >= 0.8 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  æ—¶é—´å¹³è¡¡æ€§:       {st['time_balance_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if st['time_balance_score'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  è¿‡æ¸¡è‡ªç„¶æ€§:       {st['transition_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if st['transition_score'] >= 0.6 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  ç»„ç»‡ç»“æ„:         {st['organization_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if st['organization_score'] >= 0.8 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  ç»¼åˆå¾—åˆ†:         {st['overall_score']:.1%}\n\n"

        # 3. è¯­è¨€è´¨é‡
        report += "ã€3. è¯­è¨€è´¨é‡ã€‘ æƒé‡: 20%\n"
        report += "-" * 70 + "\n"
        lq = results['language_quality']
        report += f"  è¡¨è¾¾æ¸…æ™°åº¦:       {lq['clarity_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if lq['clarity_score'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  å£è¯­åŒ–ç¨‹åº¦:       {lq['conversational_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if lq['conversational_score'] >= 0.6 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  è¯æ±‡ä¸°å¯Œåº¦:       {lq['vocabulary_richness']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if lq['vocabulary_richness'] >= 0.5 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  ä¸“ä¸šæ€§:           {lq['professionalism_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if lq['professionalism_score'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  ç»¼åˆå¾—åˆ†:         {lq['overall_score']:.1%}\n\n"

        # 4. ç»†èŠ‚ä¸°å¯Œåº¦
        report += "ã€4. ç»†èŠ‚ä¸°å¯Œåº¦ã€‘ æƒé‡: 15%\n"
        report += "-" * 70 + "\n"
        dr = results['detail_richness']
        report += f"  å†…å®¹æ‰©å±•æ¯”:       {dr['expansion_ratio_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if dr['expansion_ratio_score'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  ä¾‹å­ä½¿ç”¨:         {dr['example_usage_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if dr['example_usage_score'] >= 0.5 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  è§£é‡Šè´¨é‡:         {dr['explanation_quality']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if dr['explanation_quality'] >= 0.5 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  èƒŒæ™¯ä¿¡æ¯:         {dr['context_provision']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if dr['context_provision'] >= 0.6 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  ç»¼åˆå¾—åˆ†:         {dr['overall_score']:.1%}\n\n"

        # 5. æ—¶é—´è§„åˆ’
        report += "ã€5. æ—¶é—´è§„åˆ’ã€‘ æƒé‡: 10%\n"
        report += "-" * 70 + "\n"
        tm = results['time_management']
        total_mins = tm['total_minutes']
        total_secs = int(total_mins * 60)
        report += f"  æ€»æ—¶é•¿:           {total_mins:.1f} åˆ†é’Ÿ ({total_secs}ç§’)  "
        report += f"{'âœ“ åˆç†' if 10 <= total_mins <= 30 else 'âš  æ³¨æ„'}\n"
        report += f"  æ—¶é•¿åˆç†æ€§:       {tm['duration_appropriateness']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if tm['duration_appropriateness'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  æ—¶é—´åˆ†å¸ƒ:         {tm['time_distribution_score']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if tm['time_distribution_score'] >= 0.6 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  èŠ‚å¥ä¸€è‡´æ€§:       {tm['pace_consistency']:.1%}  "
        report += f"{'âœ“ ä¼˜ç§€' if tm['pace_consistency'] >= 0.7 else 'âœ— éœ€æ”¹è¿›'}\n"
        report += f"  ç»¼åˆå¾—åˆ†:         {tm['overall_score']:.1%}\n\n"

        # æ”¹è¿›å»ºè®®
        report += "=" * 70 + "\n"
        report += "æ”¹è¿›å»ºè®®:\n"
        report += "=" * 70 + "\n"
        suggestions = self._generate_suggestions(results)
        report += suggestions + "\n"

        # ä¼˜ç‚¹æ€»ç»“
        report += "=" * 70 + "\n"
        report += "ä¼˜ç‚¹æ€»ç»“:\n"
        report += "=" * 70 + "\n"
        strengths = self._generate_strengths(results)
        report += strengths + "\n"

        report += "=" * 70 + "\n"
        report += "è¯„ä¼°å®Œæˆ!\n"
        report += "=" * 70 + "\n"

        return report

    def _generate_suggestions(self, results: Dict) -> str:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        cc = results['content_consistency']
        st = results['structure']
        lq = results['language_quality']
        dr = results['detail_richness']
        tm = results['time_management']

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_issues = []

        # å†…å®¹ä¸€è‡´æ€§é—®é¢˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if cc['keyword_coverage'] < 0.6:
            priority_issues.append(
                " [é«˜ä¼˜å…ˆçº§] å…³é”®è¯è¦†ç›–ä¸è¶³ - ç¡®ä¿å¹»ç¯ç‰‡ä¸­çš„é‡è¦æ¦‚å¿µéƒ½åœ¨æ¼”è®²ç¨¿ä¸­ä½“ç°"
            )
        if cc['slide_title_coverage'] < 0.7:
            priority_issues.append(
                " [é«˜ä¼˜å…ˆçº§] å¹»ç¯ç‰‡æ ‡é¢˜è¦†ç›–ä¸å®Œæ•´ - æ¯å¼ å¹»ç¯ç‰‡çš„ä¸»é¢˜éƒ½åº”åœ¨æ¼”è®²ä¸­æ˜ç¡®æåŠ"
            )
        if cc['hallucination_risk_score'] > 0.4:
            priority_issues.append(
                " [é«˜ä¼˜å…ˆçº§] å¹»è§‰é£é™©è¾ƒé«˜ - å‡å°‘å¹»ç¯ç‰‡ä¸­æœªå‡ºç°çš„é¢å¤–å†…å®¹ï¼Œä¿æŒä¸€è‡´æ€§"
            )
        if cc['fact_accuracy'] < 0.7:
            priority_issues.append(
                " [é«˜ä¼˜å…ˆçº§] äº‹å®å‡†ç¡®æ€§ä¸è¶³ - ç¡®ä¿å¹»ç¯ç‰‡ä¸­çš„æ•°å­—ã€äººåç­‰å…³é”®äº‹å®è¢«å‡†ç¡®ä¼ è¾¾"
            )

        # ç»“æ„é—®é¢˜ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        if st['coherence_score'] < 0.7:
            priority_issues.append(
                " [ä¸­ä¼˜å…ˆçº§] é€»è¾‘è¿è´¯æ€§æœ‰å¾…æå‡ - ç¡®ä¿æ¼”è®²å†…å®¹æŒ‰ç…§å¹»ç¯ç‰‡é¡ºåºå±•å¼€"
            )
        if st['transition_score'] < 0.5:
            priority_issues.append(
                " [ä¸­ä¼˜å…ˆçº§] ç¼ºå°‘è¿‡æ¸¡è¯­å¥ - åœ¨æ®µè½é—´æ·»åŠ 'æ¥ä¸‹æ¥'ã€'è®©æˆ‘ä»¬çœ‹çœ‹'ç­‰è¿‡æ¸¡è¯"
            )
        if st['time_balance_score'] < 0.6:
            priority_issues.append(
                " [ä¸­ä¼˜å…ˆçº§] æ—¶é—´åˆ†é…ä¸å‡è¡¡ - è°ƒæ•´å„éƒ¨åˆ†æ—¶é•¿ï¼Œé¿å…æŸäº›éƒ¨åˆ†è¿‡é•¿æˆ–è¿‡çŸ­"
            )

        # è¯­è¨€è´¨é‡é—®é¢˜ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
        if lq['conversational_score'] < 0.5:
            priority_issues.append(
                " [ä¸­ä½ä¼˜å…ˆçº§] å£è¯­åŒ–ç¨‹åº¦ä¸è¶³ - ä½¿ç”¨æ›´å¤š'æˆ‘ä»¬'ã€'è®©æˆ‘ä»¬'ç­‰å£è¯­åŒ–è¡¨è¾¾"
            )
        if lq['clarity_score'] < 0.6:
            priority_issues.append(
                " [ä¸­ä½ä¼˜å…ˆçº§] å¥å­é•¿åº¦éœ€ä¼˜åŒ– - è°ƒæ•´å¥å­é•¿åº¦ï¼Œå»ºè®®12-25è¯ä¸ºå®œ"
            )
        if lq['professionalism_score'] < 0.6:
            priority_issues.append(
                " [ä¸­ä½ä¼˜å…ˆçº§] ä¸“ä¸šæ€§ä¸è¶³ - é€‚å½“ä½¿ç”¨å¹»ç¯ç‰‡ä¸­çš„ä¸“ä¸šæœ¯è¯­å’Œæ¦‚å¿µ"
            )

        # ç»†èŠ‚é—®é¢˜ï¼ˆè¾ƒä½ä¼˜å…ˆçº§ï¼‰
        if dr['example_usage_score'] < 0.4:
            priority_issues.append(
                " [ä½ä¼˜å…ˆçº§] ç¼ºå°‘å…·ä½“ä¾‹å­ - ä¸ºæŠ½è±¡æ¦‚å¿µæ·»åŠ å…·ä½“æ¡ˆä¾‹è¯´æ˜"
            )
        if dr['explanation_quality'] < 0.4:
            priority_issues.append(
                " [ä½ä¼˜å…ˆçº§] è§£é‡Šä¸å¤Ÿå……åˆ† - ä¸ºæŠ€æœ¯æœ¯è¯­å’Œå¤æ‚æ¦‚å¿µæä¾›æ›´å¤šè§£é‡Š"
            )
        if dr['expansion_ratio_score'] < 0.5:
            priority_issues.append(
                " [ä½ä¼˜å…ˆçº§] å†…å®¹æ‰©å±•ä¸è¶³ - é€‚å½“å¢åŠ ç»†èŠ‚æè¿°ï¼Œä¸°å¯Œæ¼”è®²å†…å®¹"
            )

        # æ—¶é—´é—®é¢˜
        if tm['duration_appropriateness'] < 0.6:
            total_mins = tm['total_minutes']
            total_secs = int(total_mins * 60)
            priority_issues.append(
                f"ğŸŸ¡ [ä¸­ä½ä¼˜å…ˆçº§] æ€»æ—¶é•¿éœ€è°ƒæ•´ - å½“å‰{total_mins:.1f}åˆ†é’Ÿ({total_secs}ç§’)ï¼Œå»ºè®®è°ƒæ•´ä»¥åŒ¹é…åœºåˆéœ€æ±‚"
            )

        if priority_issues:
            suggestions = priority_issues
        else:
            suggestions = [" æ•´ä½“è´¨é‡ä¼˜ç§€ï¼Œå„é¡¹æŒ‡æ ‡å‡è¾¾æ ‡ï¼Œç»§ç»­ä¿æŒï¼"]

        # æ·»åŠ é€šç”¨å»ºè®®
        if results['overall_score'] < 0.7:
            suggestions.append("\n æ€»ä½“å»ºè®®: é‡ç‚¹å…³æ³¨å†…å®¹ä¸€è‡´æ€§å’Œç»“æ„åˆç†æ€§ï¼Œè¿™æ˜¯æ¼”è®²ç¨¿çš„åŸºç¡€")
        elif results['overall_score'] < 0.85:
            suggestions.append("\n æ€»ä½“å»ºè®®: åœ¨ä¿æŒç°æœ‰è´¨é‡çš„åŸºç¡€ä¸Šï¼Œå¯è¿›ä¸€æ­¥ä¼˜åŒ–è¯­è¨€è¡¨è¾¾å’Œç»†èŠ‚ä¸°å¯Œåº¦")

        return '\n'.join(f"  {i+1}. {s}" for i, s in enumerate(suggestions))


    def _generate_strengths(self, results: Dict) -> str:
        """ç”Ÿæˆä¼˜ç‚¹æ€»ç»“"""
        strengths = []

        cc = results['content_consistency']
        st = results['structure']
        lq = results['language_quality']
        dr = results['detail_richness']
        tm = results['time_management']

        if cc['keyword_coverage'] >= 0.75:
            strengths.append("âœ“ å…³é”®è¯è¦†ç›–å…¨é¢ï¼Œå‡†ç¡®ä¼ è¾¾äº†å¹»ç¯ç‰‡æ ¸å¿ƒå†…å®¹")
        if cc['fact_accuracy'] >= 0.8:
            strengths.append("âœ“ äº‹å®æ•°æ®å‡†ç¡®ï¼Œä¿æŒäº†è‰¯å¥½çš„ä¿¡æ¯ä¸€è‡´æ€§")
        if cc['hallucination_risk_score'] <= 0.25:
            strengths.append("âœ“ å†…å®¹å¿ å®äºåŸææ–™ï¼Œå¹»è§‰é£é™©æ§åˆ¶è‰¯å¥½")

        if st['coherence_score'] >= 0.8:
            strengths.append("âœ“ é€»è¾‘ç»“æ„æ¸…æ™°ï¼Œæ¼”è®²æµç¨‹åˆç†")
        if st['transition_score'] >= 0.65:
            strengths.append("âœ“ æ®µè½è¿‡æ¸¡è‡ªç„¶ï¼Œå¬ä¼—ä½“éªŒæµç•…")
        if st['organization_score'] >= 0.8:
            strengths.append("âœ“ æ•´ä½“ç»„ç»‡ç»“æ„å®Œæ•´ï¼Œæœ‰æ˜ç¡®çš„å¼•å…¥å’Œæ€»ç»“")

        if lq['conversational_score'] >= 0.6:
            strengths.append("âœ“ å£è¯­åŒ–è¡¨è¾¾è‡ªç„¶ï¼Œé€‚åˆç°åœºæ¼”è®²")
        if lq['clarity_score'] >= 0.75:
            strengths.append("âœ“ è¡¨è¾¾æ¸…æ™°æ˜“æ‡‚ï¼Œå¥å­é•¿åº¦é€‚ä¸­")
        if lq['professionalism_score'] >= 0.7:
            strengths.append("âœ“ ä¸“ä¸šæ€§å¼ºï¼Œæ°å½“ä½¿ç”¨äº†å­¦æœ¯æœ¯è¯­")

        if dr['example_usage_score'] >= 0.5:
            strengths.append("âœ“ åˆç†ä½¿ç”¨ä¾‹å­ï¼Œå¸®åŠ©å¬ä¼—ç†è§£")
        if dr['explanation_quality'] >= 0.5:
            strengths.append("âœ“ è§£é‡Šå……åˆ†ï¼ŒæŠ€æœ¯æ¦‚å¿µé˜è¿°æ¸…æ¥š")
        if dr['context_provision'] >= 0.65:
            strengths.append("âœ“ æä¾›äº†å……è¶³çš„èƒŒæ™¯ä¿¡æ¯")

        if tm['duration_appropriateness'] >= 0.75:
            strengths.append("âœ“ æ—¶é•¿è§„åˆ’åˆç†ï¼Œç¬¦åˆæ¼”è®²åœºåˆè¦æ±‚")
        if tm['time_distribution_score'] >= 0.7:
            strengths.append("âœ“ æ—¶é—´åˆ†é…å¾—å½“ï¼Œé‡ç‚¹çªå‡º")

        if not strengths:
            strengths = ["ç»§ç»­åŠªåŠ›ï¼Œæå‡å„é¡¹æŒ‡æ ‡"]

        return '\n'.join(f"  â€¢ {s}" for s in strengths)


# ============ ä½¿ç”¨ç¤ºä¾‹ ============

def evaluate_from_files(pdf_text: str, speech_json_path: str):
    """
    ä»PDFæ–‡æœ¬å’Œæ¼”è®²ç¨¿JSONæ–‡ä»¶è¿›è¡Œè¯„ä¼°

    Args:
        pdf_text: ä»PDFæå–çš„æ–‡æœ¬å†…å®¹
        speech_json_path: æ¼”è®²ç¨¿JSONæ–‡ä»¶è·¯å¾„
    """
    # è¯»å–æ¼”è®²ç¨¿JSON
    with open(speech_json_path, 'r', encoding='utf-8') as f:
        speech_json = f.read()

    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = SpeechEvaluator(pdf_text, speech_json)

    # ç”Ÿæˆå¹¶æ‰“å°æŠ¥å‘Š
    report = evaluator.generate_report()
    print(report)

    # ä¿å­˜æŠ¥å‘Š
    with open('evaluation_report_'+speech_json_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print("\n æŠ¥å‘Šå·²ä¿å­˜åˆ°: evaluation_report_"+speech_json_path)

    # è¿”å›è¯„ä¼°ç»“æœä¾›è¿›ä¸€æ­¥åˆ†æ
    return evaluator.evaluate_all()


if __name__ == "__main__":
    evaluate_from_files('presentation.pdf', 'speech_qwen_vl.txt')